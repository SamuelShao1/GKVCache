services:
  tgi-server:
    image: ghcr.io/huggingface/text-generation-inference:2.0.3
    container_name: tgi-server
    ports:
      - "8080:80"
    shm_size: "1g"
    runtime: nvidia

    volumes:
      - "${PWD}/data:/data"

    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    command: >
      --model-id mistralai/Mistral-7B-Instruct-v0.1
      --trust-remote-code

    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]



  semantic-proxy:
    build:
      context: ./tgi_intercept
    image: semantic-proxy
    container_name: semantic-proxy
    ports:
      - "9000:9000"
    depends_on:
      - tgi-server
    volumes:
      - ./tgi_stats:/app/statistics
    environment:
      - MODEL_ID=mistralai/Mistral-7B-Instruct-v0.1
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
